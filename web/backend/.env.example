# CogCanvas Web Backend Configuration
# Copy this file to .env: cp .env.example .env

# Server Configuration
PORT=3801
HOST=0.0.0.0

# CORS Origins (comma-separated, matches frontend port)
CORS_ORIGINS=http://localhost:3800,http://127.0.0.1:3800

# CogCanvas Configuration
# Use "mock" for development, or specify real models for production
EXTRACTOR_MODEL=mock
EMBEDDING_MODEL=mock

# Real Model Examples (uncomment to use):
# EXTRACTOR_MODEL=gpt-4o-mini
# EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================
# LLM API Configuration
# ============================================
# Note: The backend also reads from the root .env file (../../.env)
# You can configure API keys here or in the root .env

# OpenAI-compatible API Configuration
# OPENAI_API_KEY=your-api-key-here
# OPENAI_API_BASE=https://api.openai.com/v1

# Embedding API Configuration (if using API-based embeddings)
# EMBEDDING_API_KEY=your-api-key-here
# EMBEDDING_API_BASE=https://api.example.com/v1

# Session Configuration
DEFAULT_SESSION_ID=default
SESSION_TIMEOUT=3600  # seconds

# Logging
LOG_LEVEL=info
